---
title: Semantic Search with Hugging Face Inference Endpoints - Meilisearch documentation
description: This guide will walk you through the process of setting up Meilisearch with Hugging Face Inference Endpoints to enable semantic search capabilities.
---

# Semantic search with Hugging Face Inference Endpoints

## Introduction

This guide will walk you through the process of setting up Meilisearch with [Hugging Face Inference Endpoints](https://ui.endpoints.huggingface.co/) embeddings to enable semantic search capabilities. By leveraging Meilisearch's AI features and Hugging Face Inference Endpoints, you can enhance your search experience and retrieve more relevant results.

## Requirements

To follow this guide, you'll need:

- A [Meilisearch Cloud](https://www.meilisearch.com/cloud?utm_campaign=vector-search&utm_source=docs&utm_medium=huggingface-embeddings-guide) project running version 1.10 or above with the Vector store activated.
- An Hugging Face account with a deployed inference endpoint. You can sign up for a Hugging Face account at [Hugging Face](https://huggingface.co/).
- The endpoint url and API key of the deployed model on your Hugging Face account.
- No backend required.

## Setting up Meilisearch

To set up an embedder in Meilisearch, you need to configure it to your settings. You can refer to the [Meilisearch documentation](/reference/api/settings?utm_campaign=vector-search&utm_source=docs&utm_medium=huggingface-embeddings-guide#update-embedder-settings) for more details on updating the embedder settings.

Hugging Face offers a [wide variety of embedding models](https://ui.endpoints.huggingface.co/catalog?task=sentence-embeddings) you can deploy to embed the content of your documents.

Here's an example of embedder settings using [BAAI/bge-small-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5) model:

```json
{
  "hf-inference": {
    "source": "rest",
    "url": "<ENDPOINT URL>",
    "apiKey": "<API Key>",
    "dimensions": 384,
    "documentTemplate": "<Custom template (Optional, but recommended)>",
    "request": {
      "inputs": ["{{text}}", "{{..}}"]
    },
    "response": ["{{embedding}}", "{{..}}"]
  }
}
```

In this configuration:

- `source`: Specifies the source of the embedder, which is set to "rest" for using a REST API.
- `url`: Replace `<Endpoint URL>` with your actual deployed model endpoint on Hugging Face.
- `apiKey`: Replace `<API Key>` with your actual Hugging Face API key.
- `dimensions`: Specifies the dimensions of the embeddings. Set to 384 for `baai/bge-small-en-v1.5` in our example.
- `documentTemplate`: Optionally, you can provide a [custom template](/learn/ai_powered_search/getting_started_with_ai_search?utm_campaign=vector-search&utm_source=docs&utm_medium=huggingface-embeddings-guide#documenttemplate) for generating embeddings from your documents.
- `request`: Defines the request structure for the deployed model API, including the input parameters.
- `response`: Defines the expected response structure from the deployed model API, including the embedding data.

Once you've configured the embedder settings, Meilisearch will automatically generate embeddings for your documents and store them in the vector store.

It's recommended to monitor the tasks queue to ensure everything is running smoothly. You can access the tasks queue using the Cloud UI or the [Meilisearch API](/reference/api/tasks?utm_campaign=vector-search&utm_source=docs&utm_medium=huggingface-embeddings-guide#get-tasks).

## Testing semantic search

With the embedder set up, you can now perform semantic searches using Meilisearch. When you send a search query, Meilisearch will generate an embedding for the query using the configured embedder and then use it to find the most semantically similar documents in the vector store.
To perform a semantic search, you simply need to make a normal search request but include the hybrid parameter:

```json
{
  "q": "<Query made by the user>",
  "hybrid": {
    "semanticRatio": 1,
    "embedder": "hf-inference"
  }
}
```

In this request:

- `q`: Represents the user's search query.
- `hybrid`: Specifies the configuration for the hybrid search.
  - `semanticRatio`: Allows you to control the balance between semantic search and traditional search. A value of 1 indicates pure semantic search, while a value of 0 represents full-text search. You can adjust this parameter to achieve a hybrid search experience.
  - `embedder`: The name of the embedder used for generating embeddings. Make sure to use the same name as specified in the embedder configuration, which in this case is "hf-inference".

You can use the Meilisearch API or client libraries to perform searches and retrieve the relevant documents based on semantic similarity.

## Conclusion

By following this guide, you should now have Meilisearch set up with Hugging Face Inference Endpoints, enabling you to leverage semantic search capabilities in your application. Meilisearch's auto-batching and efficient handling of embeddings make it a powerful choice for integrating semantic search into your project.

To explore further configuration options for embedders, consult the [detailed documentation about the embedder setting possibilities](/reference/api/settings?utm_campaign=vector-search&utm_source=docs&utm_medium=huggingface-embeddings-guide#embedders-experimental).
